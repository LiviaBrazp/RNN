{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando o script para que o algoritmo seja processado na placa do video do PC\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential  # Certifique-se de importar Sequential\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        #Alocar memória de vídeo de forma dinâmica\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Agora defina o modelo\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential()\n",
    "\n",
    "############################################### PREVISÃO PARA VALORES DIARIOS ###############################################################################################\n",
    "\n",
    "#Preparando o algoritmo RNN para previsões da Eto diaria  \n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#Importar o banco de dados \n",
    "dados = pd.read_csv('caminho_do_arquivo.csv', sep=';')  \n",
    "\n",
    "print(dados.head())\n",
    "print(dados.columns)\n",
    "\n",
    "#Normaliza as features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dados[['rad', 'tmed', 'umi', 'vento', 'ETo']])\n",
    "\n",
    "#Converte para DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['rad', 'tmed', 'umi', 'vento', 'ETo'])\n",
    "\n",
    "#Transforma a série temporal em um formato supervisionado\n",
    "def series_to_supervised(data, n_in=24, n_out=1):\n",
    "    cols, names = list(), list()\n",
    "    #input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [f'{col_name}(t-{i})' for col_name in data.columns]\n",
    "\n",
    "    #forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(data.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [f'{col_name}(t)' for col_name in data.columns]\n",
    "        else:\n",
    "            names += [f'{col_name}(t+{i})' for col_name in data.columns]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "reframed = series_to_supervised(scaled_df, n_in=24, n_out=1)\n",
    "\n",
    "#Divide os dados em treino e teste\n",
    "values = reframed.values\n",
    "n_train = int(0.9 * len(reframed))  #Valor ajustavel\n",
    "train = values[:n_train, :]\n",
    "test = values[n_train:, :]\n",
    "\n",
    "#Verifica a quantidade de dados nos conjuntos de treino e teste\n",
    "print(f\"Dimensões do conjunto de treinamento: {train.shape}\")\n",
    "print(f\"Dimensões do conjunto de teste: {test.shape}\")\n",
    "\n",
    "#Separa inputs e outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -5]  #Seleciona a coluna ETo\n",
    "test_X, test_y = test[:, :-1], test[:, -5]\n",
    "\n",
    "#Redimensiona o input para o formato 3D [amostras, passos de tempo, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "\n",
    "#Definindo o modelo RNN com camadas Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(100, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "model.add(SimpleRNN(50, return_sequences=True))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Compilando o modelo\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "#Adicionando a função early stopping para evitar o overfitting\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "#Treinando o modelo com EarlyStopping\n",
    "history = model.fit(train_X, train_y, epochs=1000, batch_size=90, \n",
    "                    validation_data=(test_X, test_y), verbose=2, \n",
    "                    shuffle=False, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plota o histórico de treinamento e validação\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "#Faz as previsões com o conjunto de teste\n",
    "y_pred = model.predict(test_X)\n",
    "\n",
    "#Caso a saída do modelo seja tridimensional, redimensione-a para bidimensional\n",
    "if y_pred.ndim > 2:\n",
    "    y_pred = y_pred.squeeze()\n",
    "\n",
    "\n",
    "#Calcula o RMSE (Root Mean Squared Error)\n",
    "rmse = sqrt(mean_squared_error(test_y, y_pred))\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "#Calcular o MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(test_y, y_pred)\n",
    "print('MSE:', mse)\n",
    "\n",
    "#Calcula o MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(test_y, y_pred)\n",
    "print('MAE:', mae)\n",
    "\n",
    "\n",
    "#Fazendo a previsão\n",
    "future_input = test_X[-1].reshape((1, 1, test_X.shape[2]))  #Usa o último conjunto de teste como entrada\n",
    "#Faz a revisão para os próximos 15 dias \n",
    "future_predictions = []\n",
    "\n",
    "for i in range(15):\n",
    "    next_prediction = model.predict(future_input)\n",
    "    future_predictions.append(next_prediction[0, 0])\n",
    "    future_input = np.roll(future_input, -1, axis=1)\n",
    "    future_input[0, 0, -1] = next_prediction[0, 0]\n",
    "\n",
    "#Inverte a escala das previsões\n",
    "scaled_inv = scaler.inverse_transform(np.concatenate((np.zeros((15, 4)), np.array(future_predictions).reshape(-1, 1)), axis=1))\n",
    "predicted_ETo = scaled_inv[:, -1]\n",
    "\n",
    "#Exibe o resultado das previsões\n",
    "print('Previsões para os próximos 15 dias:')\n",
    "print(predicted_ETo)\n",
    "\n",
    "#Salva as previsões em uma planilha\n",
    "\n",
    "df_predictions = pd.DataFrame({'Predicted_ETo': predicted_ETo})\n",
    "df_predictions.to_excel('RNN_diario.xlsx', index=False)\n",
    "\n",
    "\n",
    "############################################### PREVISÃO PARA VALORES HORARIOS ###############################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "#Importando o banco de dados \n",
    "dados = pd.read_csv('caminho_do_arquivo.csv', sep=';')  \n",
    "\n",
    "print(dados.head())\n",
    "print(dados.columns)\n",
    "\n",
    "#Normalizando as features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dados[['rad', 'tmed', 'umi', 'vento', 'ETo']])\n",
    "\n",
    "#Convertendo para DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['rad', 'tmed', 'umi', 'vento', 'ETo'])\n",
    "\n",
    "#Transformando a série temporal em um formato supervisionado\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    cols, names = list(), list()\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [f'{col_name}(t-{i})' for col_name in data.columns]\n",
    "\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(data.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [f'{col_name}(t)' for col_name in data.columns]\n",
    "        else:\n",
    "            names += [f'{col_name}(t+{i})' for col_name in data.columns]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "reframed = series_to_supervised(scaled_df, n_in=24, n_out=1)\n",
    "\n",
    "#Dividindo o conjunto em treino e teste\n",
    "values = reframed.values\n",
    "n_train = int(0.7 * len(reframed))  #Valor ajustavel \n",
    "train = values[:n_train, :]\n",
    "test = values[n_train:, :]\n",
    "\n",
    "#Separando inputs e outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "#Redimensionando o input para 3D [amostras, passos de tempo, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "#Definindo a arquitetura da rede RNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(100, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "model.add(SimpleRNN(50, return_sequences=True))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Compilando o modelo\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "#Adicionando a função early stopping para evitar o overfitting\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "#Treinando o modelo com EarlyStopping\n",
    "model.fit(train_X, train_y, epochs=100, batch_size=90, \n",
    "          validation_data=(test_X, test_y), verbose=2, \n",
    "          shuffle=False, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "#Calculando as métricas de erro\n",
    "\n",
    "#Calcula o RMSE (Root Mean Squared Error)\n",
    "rmse = sqrt(mean_squared_error(test_y, y_pred))\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "#Calcula o MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(test_y, y_pred)\n",
    "print('MSE:', mse)\n",
    "\n",
    "#Calcula o MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(test_y, y_pred)\n",
    "print('MAE:', mae)\n",
    "\n",
    "\n",
    "#Fazendo as previsões\n",
    "#Número de horas por dia\n",
    "hours_per_day = 24\n",
    "\n",
    "#Número de dias futuros para prever\n",
    "num_days = 15\n",
    "\n",
    "#Definindo a sequência inicial para fazer as previsões\n",
    "last_test_sequence = test_X[-1].reshape((1, test_X.shape[1], test_X.shape[2]))\n",
    "\n",
    "#Lista para armazenar as previsões\n",
    "future_predictions = []\n",
    "\n",
    "for day in range(num_days):\n",
    "    for hour in range(hours_per_day):\n",
    "        next_prediction = model.predict(last_test_sequence)\n",
    "        future_predictions.append(next_prediction[0, 0]) \n",
    "        last_test_sequence = np.roll(last_test_sequence, -1, axis=1)\n",
    "        last_test_sequence[:, -1, -1] = next_prediction\n",
    "\n",
    "#Exibe as previsões para os próximos 15 dias (cada dia contendo 24 horas)\n",
    "print(\"Previsões para os próximos 15 dias (24 horas por dia):\")\n",
    "print(future_predictions)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Cria um DataFrame para armazenar os valores previstos\n",
    "data = np.array(future_predictions).reshape(num_days, hours_per_day)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Adiciona rótulos de coluna (horas do dia)\n",
    "hours_labels = [f'{hour}:00' for hour in range(hours_per_day)]\n",
    "df.columns = hours_labels\n",
    "\n",
    "#Adiciona rótulos de linha (dias)\n",
    "days_labels = [f'Dia {day + 1}' for day in range(num_days)]\n",
    "df.index = days_labels\n",
    "\n",
    "#Exporta o DataFrame para um arquivo Excel\n",
    "nome_arquivo = 'RNN_horario.xlsx'  \n",
    "df.to_excel(nome_arquivo)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
